{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#importing rquired libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671    2  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622    3  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622    3  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading dataset and giving header names\n",
    "boston_df = pd.read_csv(\"boston_dataset.csv\", names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS',\n",
    "                                                      'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV'])\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     506 non-null    float64\n",
      " 1   ZN       506 non-null    float64\n",
      " 2   INDUS    506 non-null    float64\n",
      " 3   CHAS     506 non-null    float64\n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      506 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    int64  \n",
      " 9   TAX      506 non-null    float64\n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    506 non-null    float64\n",
      " 13  MEDV     452 non-null    float64\n",
      "dtypes: float64(13), int64(1)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "#checking info of dataset\n",
    "boston_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping the rows which have empty fields\n",
    "boston_df = boston_df.dropna(axis = 0, how ='any') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 452 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     452 non-null    float64\n",
      " 1   ZN       452 non-null    float64\n",
      " 2   INDUS    452 non-null    float64\n",
      " 3   CHAS     452 non-null    float64\n",
      " 4   NOX      452 non-null    float64\n",
      " 5   RM       452 non-null    float64\n",
      " 6   AGE      452 non-null    float64\n",
      " 7   DIS      452 non-null    float64\n",
      " 8   RAD      452 non-null    int64  \n",
      " 9   TAX      452 non-null    float64\n",
      " 10  PTRATIO  452 non-null    float64\n",
      " 11  B        452 non-null    float64\n",
      " 12  LSTAT    452 non-null    float64\n",
      " 13  MEDV     452 non-null    float64\n",
      "dtypes: float64(13), int64(1)\n",
      "memory usage: 53.0 KB\n"
     ]
    }
   ],
   "source": [
    "boston_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset into independent variables and target varibale\n",
    "X = boston_df.drop(['MEDV'], axis=1)\n",
    "y = boston_df.MEDV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing and performing train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20,random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(361, 13)\n",
      "(361,)\n",
      "(91, 13)\n",
      "(91,)\n"
     ]
    }
   ],
   "source": [
    "#checking the shape of train and test dataset\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing standard scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "standard_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the standard scaler to the independent dataset\n",
    "standard_scaler.fit(X_train)\n",
    "standard_scaler.fit(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transforing the independent dsataset\n",
    "X_train_scaled = standard_scaler.transform(X_train)\n",
    "X_test_scaled = standard_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.68860867 -0.52571134  1.07518399 ...  0.86406032  0.33518515\n",
      "  -0.21766575]\n",
      " [-0.31294277 -0.52571134  1.59900053 ...  1.30210761  0.24101319\n",
      "  -0.09587999]\n",
      " [ 3.7347664  -0.52571134  1.07518399 ...  0.86406032  0.1140915\n",
      "   1.50299298]\n",
      " ...\n",
      " [ 1.14636856 -0.52571134  1.07518399 ...  0.86406032 -0.22077134\n",
      "   0.43823753]\n",
      " [-0.53635275 -0.52571134  2.11867077 ...  0.3822083   0.14013346\n",
      "   1.08892141]\n",
      " [ 1.11856479 -0.52571134  1.07518399 ...  0.86406032 -4.54321136\n",
      "   0.95321729]]\n",
      "[[-0.56931635  2.23062901 -1.18317018 ... -0.01203427 -0.33980153\n",
      "   0.21902317]\n",
      " [-0.55060072  0.16337374 -0.96618021 ... -1.45759033  0.1267179\n",
      "  -1.50685494]\n",
      " [-0.56218787  0.33564502 -0.75471865 ...  0.33840357  0.30519743\n",
      "  -0.72394652]\n",
      " ...\n",
      " [-0.34436472  0.16337374 -0.8777257  ... -2.28988019  0.25548095\n",
      "  -1.00231396]\n",
      " [-0.55683927 -0.52571134  0.22242725 ...  1.21449816  0.38753213\n",
      "  -0.65957405]\n",
      " [-0.53599768 -0.09503316 -0.33870604 ... -1.32617615  0.30335608\n",
      "   0.70268659]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_scaled)\n",
    "print(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing keras models\n",
    "from keras import models, layers\n",
    "seq_model = models.Sequential()\n",
    "\n",
    "#adding the layes to the model\n",
    "seq_model.add(layers.Dense(8, activation='relu', input_shape = [X_train.shape[1]]))\n",
    "seq_model.add(layers.Dense(16, activation='relu'))\n",
    "seq_model.add(layers.Dense(1))\n",
    "\n",
    "#compliling the model\n",
    "seq_model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 288 samples, validate on 73 samples\n",
      "Epoch 1/100\n",
      "288/288 [==============================] - 0s 425us/step - loss: 638.4903 - mae: 23.7044 - val_loss: 661.0659 - val_mae: 24.3141\n",
      "Epoch 2/100\n",
      "288/288 [==============================] - 0s 343us/step - loss: 624.8945 - mae: 23.4381 - val_loss: 648.5620 - val_mae: 24.0770\n",
      "Epoch 3/100\n",
      "288/288 [==============================] - 0s 42us/step - loss: 613.1836 - mae: 23.2117 - val_loss: 636.0702 - val_mae: 23.8397\n",
      "Epoch 4/100\n",
      "288/288 [==============================] - 0s 39us/step - loss: 601.2833 - mae: 22.9766 - val_loss: 623.2056 - val_mae: 23.5936\n",
      "Epoch 5/100\n",
      "288/288 [==============================] - 0s 40us/step - loss: 588.9628 - mae: 22.7301 - val_loss: 609.9212 - val_mae: 23.3367\n",
      "Epoch 6/100\n",
      "288/288 [==============================] - 0s 41us/step - loss: 575.9673 - mae: 22.4740 - val_loss: 595.3397 - val_mae: 23.0524\n",
      "Epoch 7/100\n",
      "288/288 [==============================] - 0s 41us/step - loss: 562.0211 - mae: 22.1949 - val_loss: 579.7876 - val_mae: 22.7451\n",
      "Epoch 8/100\n",
      "288/288 [==============================] - 0s 56us/step - loss: 547.0226 - mae: 21.8884 - val_loss: 563.0045 - val_mae: 22.4093\n",
      "Epoch 9/100\n",
      "288/288 [==============================] - 0s 41us/step - loss: 531.4721 - mae: 21.5632 - val_loss: 545.9940 - val_mae: 22.0621\n",
      "Epoch 10/100\n",
      "288/288 [==============================] - 0s 40us/step - loss: 515.1097 - mae: 21.2222 - val_loss: 527.7468 - val_mae: 21.6846\n",
      "Epoch 11/100\n",
      "288/288 [==============================] - 0s 40us/step - loss: 498.2119 - mae: 20.8606 - val_loss: 509.5214 - val_mae: 21.2989\n",
      "Epoch 12/100\n",
      "288/288 [==============================] - 0s 38us/step - loss: 480.7744 - mae: 20.4755 - val_loss: 490.2681 - val_mae: 20.8808\n",
      "Epoch 13/100\n",
      "288/288 [==============================] - 0s 38us/step - loss: 462.8330 - mae: 20.0689 - val_loss: 470.8654 - val_mae: 20.4473\n",
      "Epoch 14/100\n",
      "288/288 [==============================] - 0s 38us/step - loss: 444.4323 - mae: 19.6426 - val_loss: 450.7195 - val_mae: 19.9842\n",
      "Epoch 15/100\n",
      "288/288 [==============================] - 0s 80us/step - loss: 425.4747 - mae: 19.1863 - val_loss: 430.0468 - val_mae: 19.4935\n",
      "Epoch 16/100\n",
      "288/288 [==============================] - 0s 36us/step - loss: 406.0686 - mae: 18.7093 - val_loss: 408.8557 - val_mae: 18.9724\n",
      "Epoch 17/100\n",
      "288/288 [==============================] - 0s 36us/step - loss: 386.7231 - mae: 18.2044 - val_loss: 387.9261 - val_mae: 18.4361\n",
      "Epoch 18/100\n",
      "288/288 [==============================] - 0s 34us/step - loss: 367.3171 - mae: 17.6850 - val_loss: 366.3997 - val_mae: 17.8621\n",
      "Epoch 19/100\n",
      "288/288 [==============================] - 0s 36us/step - loss: 347.9810 - mae: 17.1332 - val_loss: 345.4451 - val_mae: 17.2776\n",
      "Epoch 20/100\n",
      "288/288 [==============================] - 0s 36us/step - loss: 328.5599 - mae: 16.5545 - val_loss: 323.6258 - val_mae: 16.6375\n",
      "Epoch 21/100\n",
      "288/288 [==============================] - 0s 35us/step - loss: 309.3741 - mae: 15.9474 - val_loss: 302.4987 - val_mae: 15.9808\n",
      "Epoch 22/100\n",
      "288/288 [==============================] - 0s 37us/step - loss: 290.3437 - mae: 15.3058 - val_loss: 281.6437 - val_mae: 15.2884\n",
      "Epoch 23/100\n",
      "288/288 [==============================] - 0s 38us/step - loss: 271.9039 - mae: 14.6406 - val_loss: 260.8862 - val_mae: 14.5585\n",
      "Epoch 24/100\n",
      "288/288 [==============================] - 0s 36us/step - loss: 253.8220 - mae: 13.9525 - val_loss: 240.7579 - val_mae: 13.8300\n",
      "Epoch 25/100\n",
      "288/288 [==============================] - 0s 37us/step - loss: 236.7732 - mae: 13.2342 - val_loss: 221.8735 - val_mae: 13.0809\n",
      "Epoch 26/100\n",
      "288/288 [==============================] - 0s 36us/step - loss: 220.8391 - mae: 12.5000 - val_loss: 204.0903 - val_mae: 12.2994\n",
      "Epoch 27/100\n",
      "288/288 [==============================] - 0s 39us/step - loss: 206.2763 - mae: 11.8369 - val_loss: 187.9947 - val_mae: 11.5878\n",
      "Epoch 28/100\n",
      "288/288 [==============================] - 0s 39us/step - loss: 193.2883 - mae: 11.2419 - val_loss: 173.6869 - val_mae: 10.9599\n",
      "Epoch 29/100\n",
      "288/288 [==============================] - 0s 39us/step - loss: 181.9195 - mae: 10.7279 - val_loss: 161.0693 - val_mae: 10.3563\n",
      "Epoch 30/100\n",
      "288/288 [==============================] - 0s 37us/step - loss: 172.0667 - mae: 10.2792 - val_loss: 149.9954 - val_mae: 9.8455\n",
      "Epoch 31/100\n",
      "288/288 [==============================] - 0s 36us/step - loss: 163.4684 - mae: 9.8981 - val_loss: 140.4612 - val_mae: 9.4929\n",
      "Epoch 32/100\n",
      "288/288 [==============================] - 0s 37us/step - loss: 156.1291 - mae: 9.5770 - val_loss: 132.1402 - val_mae: 9.2148\n",
      "Epoch 33/100\n",
      "288/288 [==============================] - 0s 35us/step - loss: 149.5949 - mae: 9.3394 - val_loss: 124.7101 - val_mae: 8.9533\n",
      "Epoch 34/100\n",
      "288/288 [==============================] - 0s 36us/step - loss: 143.7813 - mae: 9.0764 - val_loss: 118.4011 - val_mae: 8.7104\n",
      "Epoch 35/100\n",
      "288/288 [==============================] - 0s 36us/step - loss: 138.3671 - mae: 8.8165 - val_loss: 112.3272 - val_mae: 8.4696\n",
      "Epoch 36/100\n",
      "288/288 [==============================] - 0s 37us/step - loss: 133.1687 - mae: 8.5564 - val_loss: 106.5936 - val_mae: 8.2229\n",
      "Epoch 37/100\n",
      "288/288 [==============================] - 0s 36us/step - loss: 127.9143 - mae: 8.3147 - val_loss: 101.1371 - val_mae: 7.9802\n",
      "Epoch 38/100\n",
      "288/288 [==============================] - 0s 36us/step - loss: 122.8414 - mae: 8.0500 - val_loss: 96.2787 - val_mae: 7.7572\n",
      "Epoch 39/100\n",
      "288/288 [==============================] - 0s 35us/step - loss: 118.0536 - mae: 7.7972 - val_loss: 91.4658 - val_mae: 7.5244\n",
      "Epoch 40/100\n",
      "288/288 [==============================] - 0s 34us/step - loss: 113.4250 - mae: 7.5526 - val_loss: 86.8137 - val_mae: 7.2936\n",
      "Epoch 41/100\n",
      "288/288 [==============================] - 0s 35us/step - loss: 108.6384 - mae: 7.3101 - val_loss: 82.0774 - val_mae: 7.0431\n",
      "Epoch 42/100\n",
      "288/288 [==============================] - 0s 35us/step - loss: 104.0316 - mae: 7.0699 - val_loss: 77.9102 - val_mae: 6.8292\n",
      "Epoch 43/100\n",
      "288/288 [==============================] - 0s 35us/step - loss: 99.5934 - mae: 6.8404 - val_loss: 73.8522 - val_mae: 6.6212\n",
      "Epoch 44/100\n",
      "288/288 [==============================] - 0s 36us/step - loss: 95.4052 - mae: 6.6253 - val_loss: 70.0459 - val_mae: 6.4156\n",
      "Epoch 45/100\n",
      "288/288 [==============================] - 0s 39us/step - loss: 91.2752 - mae: 6.4367 - val_loss: 66.3632 - val_mae: 6.2089\n",
      "Epoch 46/100\n",
      "288/288 [==============================] - 0s 37us/step - loss: 87.3695 - mae: 6.2387 - val_loss: 62.8414 - val_mae: 6.0084\n",
      "Epoch 47/100\n",
      "288/288 [==============================] - 0s 33us/step - loss: 83.4769 - mae: 6.0404 - val_loss: 59.3759 - val_mae: 5.7977\n",
      "Epoch 48/100\n",
      "288/288 [==============================] - 0s 36us/step - loss: 79.6976 - mae: 5.8764 - val_loss: 56.1984 - val_mae: 5.6109\n",
      "Epoch 49/100\n",
      "288/288 [==============================] - 0s 35us/step - loss: 76.0529 - mae: 5.7052 - val_loss: 53.1541 - val_mae: 5.4313\n",
      "Epoch 50/100\n",
      "288/288 [==============================] - 0s 35us/step - loss: 72.5606 - mae: 5.5326 - val_loss: 50.3929 - val_mae: 5.2649\n",
      "Epoch 51/100\n",
      "288/288 [==============================] - 0s 35us/step - loss: 69.2473 - mae: 5.3702 - val_loss: 47.7489 - val_mae: 5.0946\n",
      "Epoch 52/100\n",
      "288/288 [==============================] - 0s 36us/step - loss: 66.2434 - mae: 5.2000 - val_loss: 45.3623 - val_mae: 4.9422\n",
      "Epoch 53/100\n",
      "288/288 [==============================] - 0s 35us/step - loss: 63.3321 - mae: 5.0678 - val_loss: 43.1453 - val_mae: 4.8168\n",
      "Epoch 54/100\n",
      "288/288 [==============================] - 0s 36us/step - loss: 60.4113 - mae: 4.9028 - val_loss: 40.8886 - val_mae: 4.6894\n",
      "Epoch 55/100\n",
      "288/288 [==============================] - 0s 35us/step - loss: 57.5566 - mae: 4.7726 - val_loss: 38.8811 - val_mae: 4.5683\n",
      "Epoch 56/100\n",
      "288/288 [==============================] - 0s 34us/step - loss: 54.7840 - mae: 4.6208 - val_loss: 36.9799 - val_mae: 4.4492\n",
      "Epoch 57/100\n",
      "288/288 [==============================] - 0s 35us/step - loss: 52.2164 - mae: 4.5144 - val_loss: 35.4825 - val_mae: 4.3479\n",
      "Epoch 58/100\n",
      "288/288 [==============================] - 0s 34us/step - loss: 49.7966 - mae: 4.3951 - val_loss: 33.9578 - val_mae: 4.2520\n",
      "Epoch 59/100\n",
      "288/288 [==============================] - 0s 36us/step - loss: 47.3290 - mae: 4.2724 - val_loss: 32.5891 - val_mae: 4.1598\n",
      "Epoch 60/100\n",
      "288/288 [==============================] - 0s 36us/step - loss: 45.0620 - mae: 4.1672 - val_loss: 31.2734 - val_mae: 4.0671\n",
      "Epoch 61/100\n",
      "288/288 [==============================] - 0s 37us/step - loss: 42.8913 - mae: 4.0812 - val_loss: 30.2059 - val_mae: 3.9790\n",
      "Epoch 62/100\n",
      "288/288 [==============================] - 0s 36us/step - loss: 40.9339 - mae: 4.0030 - val_loss: 29.3528 - val_mae: 3.9383\n",
      "Epoch 63/100\n",
      "288/288 [==============================] - 0s 38us/step - loss: 39.1425 - mae: 3.8926 - val_loss: 28.4311 - val_mae: 3.8813\n",
      "Epoch 64/100\n",
      "288/288 [==============================] - 0s 35us/step - loss: 37.5660 - mae: 3.8319 - val_loss: 27.7350 - val_mae: 3.8420\n",
      "Epoch 65/100\n",
      "288/288 [==============================] - 0s 35us/step - loss: 36.0548 - mae: 3.7759 - val_loss: 27.1216 - val_mae: 3.8124\n",
      "Epoch 66/100\n",
      "288/288 [==============================] - 0s 35us/step - loss: 34.6456 - mae: 3.6949 - val_loss: 26.5499 - val_mae: 3.7754\n",
      "Epoch 67/100\n",
      "288/288 [==============================] - 0s 35us/step - loss: 33.4231 - mae: 3.6439 - val_loss: 26.1007 - val_mae: 3.7550\n",
      "Epoch 68/100\n",
      "288/288 [==============================] - 0s 35us/step - loss: 32.2297 - mae: 3.5814 - val_loss: 25.5219 - val_mae: 3.7331\n",
      "Epoch 69/100\n",
      "288/288 [==============================] - 0s 34us/step - loss: 31.3061 - mae: 3.5406 - val_loss: 24.9580 - val_mae: 3.7037\n",
      "Epoch 70/100\n",
      "288/288 [==============================] - 0s 34us/step - loss: 30.4403 - mae: 3.4967 - val_loss: 24.5390 - val_mae: 3.6820\n",
      "Epoch 71/100\n",
      "288/288 [==============================] - 0s 35us/step - loss: 29.5932 - mae: 3.4789 - val_loss: 24.2529 - val_mae: 3.6746\n",
      "Epoch 72/100\n",
      "288/288 [==============================] - 0s 36us/step - loss: 28.8590 - mae: 3.4186 - val_loss: 23.8730 - val_mae: 3.6450\n",
      "Epoch 73/100\n",
      "288/288 [==============================] - 0s 34us/step - loss: 28.1705 - mae: 3.3818 - val_loss: 23.5495 - val_mae: 3.6191\n",
      "Epoch 74/100\n",
      "288/288 [==============================] - 0s 35us/step - loss: 27.5593 - mae: 3.3548 - val_loss: 23.3257 - val_mae: 3.6070\n",
      "Epoch 75/100\n",
      "288/288 [==============================] - 0s 37us/step - loss: 27.1087 - mae: 3.3254 - val_loss: 23.0821 - val_mae: 3.5893\n",
      "Epoch 76/100\n",
      "288/288 [==============================] - 0s 34us/step - loss: 26.6030 - mae: 3.3110 - val_loss: 22.9538 - val_mae: 3.5825\n",
      "Epoch 77/100\n",
      "288/288 [==============================] - 0s 34us/step - loss: 26.1384 - mae: 3.2910 - val_loss: 22.8158 - val_mae: 3.5756\n",
      "Epoch 78/100\n",
      "288/288 [==============================] - 0s 34us/step - loss: 25.6305 - mae: 3.2514 - val_loss: 22.5950 - val_mae: 3.5575\n",
      "Epoch 79/100\n",
      "288/288 [==============================] - 0s 34us/step - loss: 25.1438 - mae: 3.2445 - val_loss: 22.4902 - val_mae: 3.5516\n",
      "Epoch 80/100\n",
      "288/288 [==============================] - 0s 35us/step - loss: 24.7046 - mae: 3.2006 - val_loss: 22.3910 - val_mae: 3.5466\n",
      "Epoch 81/100\n",
      "288/288 [==============================] - 0s 37us/step - loss: 24.3590 - mae: 3.1830 - val_loss: 22.1854 - val_mae: 3.5338\n",
      "Epoch 82/100\n",
      "288/288 [==============================] - 0s 35us/step - loss: 23.9101 - mae: 3.1531 - val_loss: 22.0385 - val_mae: 3.5269\n",
      "Epoch 83/100\n",
      "288/288 [==============================] - 0s 35us/step - loss: 23.5630 - mae: 3.1401 - val_loss: 21.9833 - val_mae: 3.5151\n",
      "Epoch 84/100\n",
      "288/288 [==============================] - 0s 35us/step - loss: 23.2309 - mae: 3.1089 - val_loss: 21.8281 - val_mae: 3.5172\n",
      "Epoch 85/100\n",
      "288/288 [==============================] - 0s 34us/step - loss: 22.8420 - mae: 3.0900 - val_loss: 21.7560 - val_mae: 3.5061\n",
      "Epoch 86/100\n",
      "288/288 [==============================] - 0s 35us/step - loss: 22.5596 - mae: 3.0688 - val_loss: 21.6090 - val_mae: 3.5012\n",
      "Epoch 87/100\n",
      "288/288 [==============================] - 0s 36us/step - loss: 22.3102 - mae: 3.0432 - val_loss: 21.5048 - val_mae: 3.4939\n",
      "Epoch 88/100\n",
      "288/288 [==============================] - 0s 36us/step - loss: 22.0112 - mae: 3.0402 - val_loss: 21.4915 - val_mae: 3.4823\n",
      "Epoch 89/100\n",
      "288/288 [==============================] - 0s 35us/step - loss: 21.7587 - mae: 3.0064 - val_loss: 21.3676 - val_mae: 3.4802\n",
      "Epoch 90/100\n",
      "288/288 [==============================] - 0s 35us/step - loss: 21.5164 - mae: 3.0023 - val_loss: 21.3507 - val_mae: 3.4666\n",
      "Epoch 91/100\n",
      "288/288 [==============================] - 0s 36us/step - loss: 21.1853 - mae: 2.9800 - val_loss: 21.2213 - val_mae: 3.4645\n",
      "Epoch 92/100\n",
      "288/288 [==============================] - 0s 36us/step - loss: 21.0063 - mae: 2.9672 - val_loss: 21.1293 - val_mae: 3.4608\n",
      "Epoch 93/100\n",
      "288/288 [==============================] - 0s 35us/step - loss: 20.7240 - mae: 2.9426 - val_loss: 21.1667 - val_mae: 3.4473\n",
      "Epoch 94/100\n",
      "288/288 [==============================] - 0s 34us/step - loss: 20.5195 - mae: 2.9253 - val_loss: 20.9770 - val_mae: 3.4489\n",
      "Epoch 95/100\n",
      "288/288 [==============================] - 0s 33us/step - loss: 20.3191 - mae: 2.9343 - val_loss: 20.9101 - val_mae: 3.4506\n",
      "Epoch 96/100\n",
      "288/288 [==============================] - 0s 36us/step - loss: 20.0622 - mae: 2.8932 - val_loss: 20.8264 - val_mae: 3.4307\n",
      "Epoch 97/100\n",
      "288/288 [==============================] - 0s 36us/step - loss: 19.9269 - mae: 2.8983 - val_loss: 20.7128 - val_mae: 3.4328\n",
      "Epoch 98/100\n",
      "288/288 [==============================] - 0s 36us/step - loss: 19.7541 - mae: 2.8818 - val_loss: 20.6413 - val_mae: 3.4277\n",
      "Epoch 99/100\n",
      "288/288 [==============================] - 0s 38us/step - loss: 19.5630 - mae: 2.8626 - val_loss: 20.4677 - val_mae: 3.4417\n",
      "Epoch 100/100\n",
      "288/288 [==============================] - 0s 35us/step - loss: 19.4330 - mae: 2.8640 - val_loss: 20.4263 - val_mae: 3.4233\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "train_model = seq_model.fit(X_train_scaled, y_train, validation_split=0.2, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/91 [==============================] - 0s 28us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[14.249592068431141, 2.905672788619995]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluating the model\n",
    "seq_model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18.502903]\n",
      " [21.72413 ]]\n",
      "483    21.8\n",
      "132    23.0\n",
      "Name: MEDV, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#predicting the result from the model\n",
    "predict = X_train_scaled[:2]\n",
    "prediction = seq_model.predict(predict)\n",
    "print(prediction)\n",
    "print(y_train[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24.741747]\n",
      " [45.213173]\n",
      " [22.893396]\n",
      " [26.74046 ]\n",
      " [22.801376]\n",
      " [28.025581]\n",
      " [24.98629 ]\n",
      " [18.882563]\n",
      " [26.716309]\n",
      " [17.531857]]\n",
      "286    20.1\n",
      "282    46.0\n",
      "83     22.9\n",
      "252    29.6\n",
      "50     19.7\n",
      "236    25.1\n",
      "81     23.9\n",
      "450    13.4\n",
      "300    24.8\n",
      "491    13.6\n",
      "Name: MEDV, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "predict_all = seq_model.predict(X_test_scaled)\n",
    "print(predict_all[0:10])\n",
    "print(y_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting the model loss\n",
    "plt.plot(train_model.history['loss'])\n",
    "plt.plot(train_model.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
